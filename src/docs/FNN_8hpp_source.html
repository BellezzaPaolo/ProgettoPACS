<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>My Project: FNN.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">My Project
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function() { init_codefold(0); });
/* @license-end */
</script>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">FNN.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="FNN_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span><span class="preprocessor">#ifndef FNN_HPP</span></div>
<div class="line"><a id="l00002" name="l00002"></a><span class="lineno">    2</span><span class="preprocessor">#define FNN_HPP</span></div>
<div class="line"><a id="l00003" name="l00003"></a><span class="lineno">    3</span> </div>
<div class="line"><a id="l00004" name="l00004"></a><span class="lineno">    4</span><span class="preprocessor">#include &lt;torch/torch.h&gt;</span></div>
<div class="line"><a id="l00005" name="l00005"></a><span class="lineno">    5</span><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><a id="l00006" name="l00006"></a><span class="lineno">    6</span><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a id="l00007" name="l00007"></a><span class="lineno">    7</span><span class="preprocessor">#include &lt;stdexcept&gt;</span></div>
<div class="line"><a id="l00008" name="l00008"></a><span class="lineno">    8</span><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span> </div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno"><a class="line" href="FNN_8hpp.html#a83689fe2ddb97d5e71cfdbaa2523e0cd">   24</a></span><span class="keyword">enum class</span> <a class="code hl_enumeration" href="FNN_8hpp.html#a83689fe2ddb97d5e71cfdbaa2523e0cd">Activation</a> { Relu, Tanh, Sigmoid, Linear };</div>
<div class="line"><a id="l00025" name="l00025"></a><span class="lineno">   25</span> </div>
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno"><a class="line" href="FNN_8hpp.html#a316de75f211bc105b8fbe040e6d6922e">   29</a></span><span class="keyword">enum class</span> <a class="code hl_enumeration" href="FNN_8hpp.html#a316de75f211bc105b8fbe040e6d6922e">Initializer_weight</a> {One, Uniform, Glorot_Uniform, He_Uniform, Glorot_Norm, He_Norm};</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span> </div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno"><a class="line" href="FNN_8hpp.html#a1bb6c6c4c2111fc58731c00e4b2d30ab">   34</a></span><span class="keyword">enum class</span> <a class="code hl_enumeration" href="FNN_8hpp.html#a1bb6c6c4c2111fc58731c00e4b2d30ab">Initializer_bias</a> {Constant, Uniform, Normal};</div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span> </div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span><span class="keyword">template</span> &lt;Activation A&gt;</div>
<div class="foldopen" id="foldopen00050" data-start="{" data-end="};">
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno"><a class="line" href="classFNN.html">   50</a></span><span class="keyword">class </span><a class="code hl_class" href="classFNN.html">FNN</a> final : <span class="keyword">public</span> torch::nn::Module {</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>    std::vector&lt;int64_t&gt; layer_sizes_;</div>
<div class="line"><a id="l00053" name="l00053"></a><span class="lineno">   53</span>    <span class="keywordtype">int</span> depth;</div>
<div class="line"><a id="l00054" name="l00054"></a><span class="lineno">   54</span>    torch::nn::ModuleList layers{<span class="keyword">nullptr</span>};</div>
<div class="line"><a id="l00055" name="l00055"></a><span class="lineno">   55</span> </div>
<div class="line"><a id="l00059" name="l00059"></a><span class="lineno">   59</span>    torch::Tensor apply_activation(<span class="keyword">const</span> torch::Tensor&amp; x)<span class="keyword"> const</span>{</div>
<div class="line"><a id="l00060" name="l00060"></a><span class="lineno">   60</span>        <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (A == Activation::Relu)</div>
<div class="line"><a id="l00061" name="l00061"></a><span class="lineno">   61</span>            <span class="keywordflow">return</span> torch::relu(x);</div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno">   62</span>        <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (A == Activation::Tanh)</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>            <span class="keywordflow">return</span> torch::tanh(x);</div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span>        <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (A == Activation::Sigmoid)</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>            <span class="keywordflow">return</span> torch::sigmoid(x);</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>        <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>            <span class="keywordflow">return</span> x;</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span>        }</div>
<div class="line"><a id="l00070" name="l00070"></a><span class="lineno">   70</span>    }</div>
<div class="line"><a id="l00071" name="l00071"></a><span class="lineno">   71</span> </div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>    <span class="comment">// torch::Tensor apply_activation_runtime(const torch::Tensor&amp; x) const;</span></div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span> </div>
<div class="line"><a id="l00080" name="l00080"></a><span class="lineno">   80</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno"><a class="line" href="classFNN.html#a3f0361bf0185f3427d8ce16ca07a2b2f">   86</a></span>    <a class="code hl_function" href="classFNN.html#a3f0361bf0185f3427d8ce16ca07a2b2f">FNN</a>() = <span class="keywordflow">default</span>;</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span> </div>
<div class="foldopen" id="foldopen00095" data-start="{" data-end="}">
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno"><a class="line" href="classFNN.html#a0046759d2225cb1bbf290966e2ed1fbb">   95</a></span>    <span class="keyword">explicit</span> <a class="code hl_function" href="classFNN.html#a0046759d2225cb1bbf290966e2ed1fbb">FNN</a>(<span class="keyword">const</span> std::vector&lt;int64_t&gt;&amp; layer_sizes): layer_sizes_(layer_sizes){</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>        <span class="keywordflow">if</span>(layer_sizes_.size() &lt; 2)</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>            <span class="keywordflow">throw</span> std::invalid_argument(<span class="stringliteral">&quot;PINN requires at least input and output layer&quot;</span>);</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span> </div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>        layers = register_module(<span class="stringliteral">&quot;linear&quot;</span>, torch::nn::ModuleList());</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>        <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i = 1; i &lt; layer_sizes_.size(); ++i){</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>            layers-&gt;push_back(torch::nn::Linear(</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>                torch::nn::LinearOptions(layer_sizes_[i - 1], layer_sizes_[i])</div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>            ));</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>        }</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span> </div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>        depth = layers-&gt;size();</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>    }</div>
</div>
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno">  108</span> </div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno"><a class="line" href="classFNN.html#aad9a98a5baf24ef3bf56d222fc67dc8e">  112</a></span>    <span class="keyword">const</span> std::vector&lt;int64_t&gt;&amp; <a class="code hl_function" href="classFNN.html#aad9a98a5baf24ef3bf56d222fc67dc8e">get_layer_sizes</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> layer_sizes_; }</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span> </div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno"><a class="line" href="classFNN.html#a5850c0802934f85019ea3eb8566c8b68">  117</a></span>    <a class="code hl_enumeration" href="FNN_8hpp.html#a83689fe2ddb97d5e71cfdbaa2523e0cd">Activation</a> <a class="code hl_function" href="classFNN.html#a5850c0802934f85019ea3eb8566c8b68">get_activation</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> A; }</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span> </div>
<div class="foldopen" id="foldopen00125" data-start="{" data-end="}">
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno"><a class="line" href="classFNN.html#a1dfe03144a7b3b160b341e639c91ee58">  125</a></span>    torch::Tensor <a class="code hl_function" href="classFNN.html#a1dfe03144a7b3b160b341e639c91ee58">forward</a>(torch::Tensor x){</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>        <span class="keywordflow">if</span>(x.dim() == 1)</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>            x = x.unsqueeze(0);</div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span> </div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>        TORCH_CHECK(!layer_sizes_.empty(), <span class="stringliteral">&quot;FNN is not initialized with layer sizes&quot;</span>);</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>        TORCH_CHECK(x.size(-1) == layer_sizes_.front(), <span class="stringliteral">&quot;Expected input dim &quot;</span>, layer_sizes_.front(), <span class="stringliteral">&quot;, got &quot;</span>, x.size(-1));</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span> </div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>        <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> i = 0; i &lt; depth; ++i){</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>            x = layers[i]-&gt;as&lt;torch::nn::Linear&gt;()-&gt;<a class="code hl_function" href="classFNN.html#a1dfe03144a7b3b160b341e639c91ee58">forward</a>(x);</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>            <span class="keywordflow">if</span>(i != depth - 1)</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>                x = apply_activation(x);</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>        }</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>        <span class="keywordflow">return</span> x;</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>    }</div>
</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span> </div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>    <span class="keyword">template</span> &lt;Initializer_weight Iw&gt;</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>    <span class="keywordtype">void</span> <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">initialize_weight</a>();</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span> </div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>    <span class="keyword">template</span> &lt;Initializer_bias Ib&gt;</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>    <span class="keywordtype">void</span> <a class="code hl_function" href="classFNN.html#aff4c06e677c981c1c3362909300b0baf">initialize_bias</a>(<span class="keyword">const</span> <span class="keywordtype">double</span> constant_value = 0.0);</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span> </div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno">  162</span>    <span class="keyword">template</span> &lt;Initializer_weight Iw, Initializer_bias Ib&gt;</div>
<div class="foldopen" id="foldopen00163" data-start="{" data-end="}">
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno"><a class="line" href="classFNN.html#aac1918e524f6b9f46dde27fcc635caa9">  163</a></span>    <span class="keywordtype">void</span> <a class="code hl_function" href="classFNN.html#aac1918e524f6b9f46dde27fcc635caa9">initialize</a>(<span class="keyword">const</span> <span class="keywordtype">double</span> bias_constant_value = 0.0){</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno">  164</span>        <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">initialize_weight&lt;Iw&gt;</a>();</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span>        <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">initialize_bias&lt;Ib&gt;</a>(<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">bias_constant_value</a>);</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span> </div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno">  168</span>    }</div>
</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno">  169</span> </div>
<div class="foldopen" id="foldopen00173" data-start="{" data-end="}">
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno"><a class="line" href="classFNN.html#ac79da78d18dd6c84852c1dc03ed9466a">  173</a></span>    <span class="keywordtype">void</span> <a class="code hl_function" href="classFNN.html#ac79da78d18dd6c84852c1dc03ed9466a">print</a>()<span class="keyword"> const</span>{</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno">  174</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;The network has shape: [ &quot;</span>;</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno">  175</span>        <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">j</a>=0; <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">j</a>&lt;layer_sizes_.size(); ++<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">j</a>){</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno">  176</span>            std::cout &lt;&lt; layer_sizes_[<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">j</a>];</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>            <span class="keywordflow">if</span> (<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">j</a> + 1 &lt; layer_sizes_.size()) std::cout &lt;&lt; <span class="stringliteral">&quot;, &quot;</span>;</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>        }</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>        std::cout &lt;&lt; <span class="stringliteral">&quot; ]&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span> </div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>        std::cout &lt;&lt; <span class="stringliteral">&quot;Layers: &quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">i</a> = 1; <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">i</a> &lt; layer_sizes_.size(); ++<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">i</a>){</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>            std::string <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">act_type</a>;</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>            <span class="keywordflow">if</span>(<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">i</a> &lt; layer_sizes_.size() - 1){</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>                <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">A</a> == Activation::Relu) <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">act_type</a> = <span class="stringliteral">&quot;relu&quot;</span>;</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>                <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">A</a> == Activation::Tanh) <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">act_type</a> = <span class="stringliteral">&quot;tanh&quot;</span>;</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>                <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">A</a> == Activation::Sigmoid) <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">act_type</a> = <span class="stringliteral">&quot;sigmoid&quot;</span>;</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>                <span class="keywordflow">else</span> <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">act_type</a> = <span class="stringliteral">&quot;linear&quot;</span>;</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>            } </div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>            <span class="keywordflow">else</span>{</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>                <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">act_type</a> =  <span class="stringliteral">&quot;linear/output&quot;</span>;</div>
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno">  192</span>            }</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>            std::cout &lt;&lt; <span class="stringliteral">&quot;Dense &quot;</span> &lt;&lt; (<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">i</a>) &lt;&lt; <span class="stringliteral">&quot; &quot;</span> &lt;&lt; <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">act_type</a> &lt;&lt; <span class="stringliteral">&quot; (&quot;</span> </div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>                        &lt;&lt; layer_sizes_[<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">i</a>-1] &lt;&lt; <span class="stringliteral">&quot;x&quot;</span> &lt;&lt; layer_sizes_[<a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">i</a>] &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; std::endl;</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>        }</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>        std::cout &lt;&lt; std::endl;</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    }</div>
</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>};</div>
</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span> </div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span><span class="keyword">template</span> &lt;Activation A&gt;</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span><span class="keyword">template</span> &lt;Initializer_weight Iw&gt;</div>
<div class="foldopen" id="foldopen00202" data-start="{" data-end="}">
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno"><a class="line" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">  202</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">FNN&lt;A&gt;::initialize_weight</a>(){</div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>    <span class="keywordflow">for</span>(<span class="keyword">auto</span>&amp; m : modules(<span class="comment">/*include_self=*/</span><span class="keyword">false</span>)){</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>        <span class="keywordflow">if</span>(<span class="keyword">auto</span>* lin = <span class="keyword">dynamic_cast&lt;</span>torch::nn::LinearImpl*<span class="keyword">&gt;</span>(m.get())){</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>            <span class="keyword">const</span> <span class="keyword">auto</span> N_out = lin-&gt;weight.size(0);</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>            <span class="keyword">const</span> <span class="keyword">auto</span> N_in  = lin-&gt;weight.size(1);</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span> </div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>            <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Iw == Initializer_weight::One){</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>                torch::nn::init::ones_(lin-&gt;weight);</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>            }</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>            <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Iw == Initializer_weight::Uniform){</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>                torch::nn::init::uniform_(lin-&gt;weight, -1.0, 1.0);</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>            }</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>            <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Iw == Initializer_weight::Glorot_Uniform){</div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>                <span class="keywordtype">double</span> limit = std::sqrt(6.0 / <span class="keyword">static_cast&lt;</span><span class="keywordtype">double</span><span class="keyword">&gt;</span>(N_in + N_out));</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>                torch::nn::init::uniform_(lin-&gt;weight, -limit, limit);</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>            }</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>            <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Iw == Initializer_weight::He_Uniform){</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span>                <span class="keywordtype">double</span> limit = std::sqrt(6.0 / <span class="keyword">static_cast&lt;</span><span class="keywordtype">double</span><span class="keyword">&gt;</span>(N_in));</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>                torch::nn::init::uniform_(lin-&gt;weight, -limit, limit);</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>            }</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>            <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Iw == Initializer_weight::Glorot_Norm){</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>                <span class="keywordtype">double</span> stddev = std::sqrt(2.0 / <span class="keyword">static_cast&lt;</span><span class="keywordtype">double</span><span class="keyword">&gt;</span>(N_in + N_out));</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>                torch::nn::init::normal_(lin-&gt;weight, 0.0, stddev);</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>            }</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>            <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Iw == Initializer_weight::He_Norm){</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>                <span class="keywordtype">double</span> stddev = std::sqrt(2.0 / <span class="keyword">static_cast&lt;</span><span class="keywordtype">double</span><span class="keyword">&gt;</span>(N_in));</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>                torch::nn::init::normal_(lin-&gt;weight, 0.0, stddev);</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>            }</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>        }</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>    }</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span>}</div>
</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span> </div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span><span class="keyword">template</span> &lt;Activation A&gt;</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span><span class="keyword">template</span> &lt;Initializer_bias Ib&gt;</div>
<div class="foldopen" id="foldopen00242" data-start="{" data-end="}">
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno"><a class="line" href="classFNN.html#aff4c06e677c981c1c3362909300b0baf">  242</a></span><span class="keywordtype">void</span> <a class="code hl_function" href="classFNN.html#aff4c06e677c981c1c3362909300b0baf">FNN&lt;A&gt;::initialize_bias</a>(<span class="keyword">const</span> <span class="keywordtype">double</span> constant_value){</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>    <span class="keywordflow">for</span>(<span class="keyword">auto</span>&amp; m : modules(<span class="comment">/*include_self=*/</span><span class="keyword">false</span>)){</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>        <span class="keywordflow">if</span>(<span class="keyword">auto</span>* lin = <span class="keyword">dynamic_cast&lt;</span>torch::nn::LinearImpl*<span class="keyword">&gt;</span>(m.get())){</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>            <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Ib == Initializer_bias::Constant){</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>                torch::nn::init::constant_(lin-&gt;bias, constant_value);</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>            }</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>            <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Ib == Initializer_bias::Uniform){</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>                torch::nn::init::uniform_(lin-&gt;bias, -1.0, 1.0);</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>            }</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>            <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (Ib == Initializer_bias::Normal){</div>
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno">  255</span>                torch::nn::init::normal_(lin-&gt;bias, 0.0, 0.05);</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>            }</div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>        }</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>    }</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>}</div>
</div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span> </div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span><span class="preprocessor">#endif</span></div>
<div class="ttc" id="aFNN_8hpp_html_a1bb6c6c4c2111fc58731c00e4b2d30ab"><div class="ttname"><a href="FNN_8hpp.html#a1bb6c6c4c2111fc58731c00e4b2d30ab">Initializer_bias</a></div><div class="ttdeci">Initializer_bias</div><div class="ttdoc">Supported bias initialization strategies.</div><div class="ttdef"><b>Definition</b> FNN.hpp:34</div></div>
<div class="ttc" id="aFNN_8hpp_html_a316de75f211bc105b8fbe040e6d6922e"><div class="ttname"><a href="FNN_8hpp.html#a316de75f211bc105b8fbe040e6d6922e">Initializer_weight</a></div><div class="ttdeci">Initializer_weight</div><div class="ttdoc">Supported weight initialization strategies.</div><div class="ttdef"><b>Definition</b> FNN.hpp:29</div></div>
<div class="ttc" id="aFNN_8hpp_html_a83689fe2ddb97d5e71cfdbaa2523e0cd"><div class="ttname"><a href="FNN_8hpp.html#a83689fe2ddb97d5e71cfdbaa2523e0cd">Activation</a></div><div class="ttdeci">Activation</div><div class="ttdoc">Supported activation functions for hidden layers.</div><div class="ttdef"><b>Definition</b> FNN.hpp:24</div></div>
<div class="ttc" id="aclassFNN_html"><div class="ttname"><a href="classFNN.html">FNN</a></div><div class="ttdoc">Fully-connected feed-forward neural network.</div><div class="ttdef"><b>Definition</b> FNN.hpp:50</div></div>
<div class="ttc" id="aclassFNN_html_a0046759d2225cb1bbf290966e2ed1fbb"><div class="ttname"><a href="classFNN.html#a0046759d2225cb1bbf290966e2ed1fbb">FNN::FNN</a></div><div class="ttdeci">FNN(const std::vector&lt; int64_t &gt; &amp;layer_sizes)</div><div class="ttdoc">Construct the network from layer sizes.</div><div class="ttdef"><b>Definition</b> FNN.hpp:95</div></div>
<div class="ttc" id="aclassFNN_html_a1dfe03144a7b3b160b341e639c91ee58"><div class="ttname"><a href="classFNN.html#a1dfe03144a7b3b160b341e639c91ee58">FNN::forward</a></div><div class="ttdeci">torch::Tensor forward(torch::Tensor x)</div><div class="ttdoc">Forward pass.</div><div class="ttdef"><b>Definition</b> FNN.hpp:125</div></div>
<div class="ttc" id="aclassFNN_html_a3f0361bf0185f3427d8ce16ca07a2b2f"><div class="ttname"><a href="classFNN.html#a3f0361bf0185f3427d8ce16ca07a2b2f">FNN::FNN</a></div><div class="ttdeci">FNN()=default</div><div class="ttdoc">Legacy runtime-activation implementation (disabled).</div></div>
<div class="ttc" id="aclassFNN_html_a5850c0802934f85019ea3eb8566c8b68"><div class="ttname"><a href="classFNN.html#a5850c0802934f85019ea3eb8566c8b68">FNN::get_activation</a></div><div class="ttdeci">Activation get_activation() const</div><div class="ttdoc">Get the activation configured for hidden layers.</div><div class="ttdef"><b>Definition</b> FNN.hpp:117</div></div>
<div class="ttc" id="aclassFNN_html_a692d1a25b0c4b853a22781c5d253bbf2"><div class="ttname"><a href="classFNN.html#a692d1a25b0c4b853a22781c5d253bbf2">FNN::initialize_weight</a></div><div class="ttdeci">void initialize_weight()</div><div class="ttdoc">Initialize all weights according to the selected strategy.</div><div class="ttdef"><b>Definition</b> FNN.hpp:202</div></div>
<div class="ttc" id="aclassFNN_html_aac1918e524f6b9f46dde27fcc635caa9"><div class="ttname"><a href="classFNN.html#aac1918e524f6b9f46dde27fcc635caa9">FNN::initialize</a></div><div class="ttdeci">void initialize(const double bias_constant_value=0.0)</div><div class="ttdoc">Initialize both weights and biases.</div><div class="ttdef"><b>Definition</b> FNN.hpp:163</div></div>
<div class="ttc" id="aclassFNN_html_aad9a98a5baf24ef3bf56d222fc67dc8e"><div class="ttname"><a href="classFNN.html#aad9a98a5baf24ef3bf56d222fc67dc8e">FNN::get_layer_sizes</a></div><div class="ttdeci">const std::vector&lt; int64_t &gt; &amp; get_layer_sizes() const</div><div class="ttdoc">Get the network layer sizes.</div><div class="ttdef"><b>Definition</b> FNN.hpp:112</div></div>
<div class="ttc" id="aclassFNN_html_ac79da78d18dd6c84852c1dc03ed9466a"><div class="ttname"><a href="classFNN.html#ac79da78d18dd6c84852c1dc03ed9466a">FNN::print</a></div><div class="ttdeci">void print() const</div><div class="ttdoc">Print a human-readable summary of the network architecture.</div><div class="ttdef"><b>Definition</b> FNN.hpp:173</div></div>
<div class="ttc" id="aclassFNN_html_aff4c06e677c981c1c3362909300b0baf"><div class="ttname"><a href="classFNN.html#aff4c06e677c981c1c3362909300b0baf">FNN::initialize_bias</a></div><div class="ttdeci">void initialize_bias(const double constant_value=0.0)</div><div class="ttdoc">Initialize all biases according to the selected strategy.</div><div class="ttdef"><b>Definition</b> FNN.hpp:242</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8
</small></address>
</body>
</html>
